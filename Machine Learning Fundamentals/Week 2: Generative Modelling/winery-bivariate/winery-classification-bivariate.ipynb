{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the bivariate Gaussian\n",
    "\n",
    "Our first generative model for Winery classification used just one feature. Now we use two features, modeling each class by a **bivariate Gaussian**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the univariate case, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal \n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of two features from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to plot the distribution of two features from a particular winery. We will use several helper functions for this. It is worth understanding each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first helper function fits a Gaussian to a data set, restricting attention to specified features.\n",
    "It returns the mean and covariance matrix of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian to a data set using the selected features\n",
    "def fit_gaussian(x, features):\n",
    "    mu = np.mean(x[:,features], axis=0)\n",
    "    covar = np.cov(x[:,features], rowvar=0, bias=1)\n",
    "    return mu, covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's look at the Gaussian we get for winery 1, using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "[13.78534884  2.99627907]\n",
      "Covariance matrix:\n",
      "[[0.23325279 0.07526874]\n",
      " [0.07526874 0.15240941]]\n"
     ]
    }
   ],
   "source": [
    "f1 = 0\n",
    "f2 = 6\n",
    "label = 1\n",
    "mu, covar = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "print(\"Mean:\\n\" + str(mu))\n",
    "print(\"Covariance matrix:\\n\" + str(covar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a routine for displaying points sampled from a two-dimensional Gaussian, as well as a few contour lines. Part of doing this involves deciding what range to use for each axis. We begin with a little helper function that takes as input an array of numbers (values along a single feature) and returns the range in which these numbers lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the range within which an array of numbers lie, with a little buffer\n",
    "def find_range(x):\n",
    "    lower = min(x)\n",
    "    upper = max(x)\n",
    "    width = upper - lower\n",
    "    lower = lower - 0.2 * width\n",
    "    upper = upper + 0.2 * width\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a routine that plots a few contour lines of a given two-dimensional Gaussian.\n",
    "It takes as input:\n",
    "* `mu`, `cov`: the parameters of the Gaussian\n",
    "* `x1g`, `x2g`: the grid (along the two axes) at which the density is to be computed\n",
    "* `col`: the color of the contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(mu, cov, x1g, x2g, col):\n",
    "    rv = multivariate_normal(mean=mu, cov=cov)\n",
    "    z = np.zeros((len(x1g),len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            z[j,i] = rv.logpdf([x1g[i], x2g[j]]) \n",
    "    sign, logdet = np.linalg.slogdet(cov)\n",
    "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet)\n",
    "    for offset in range(1,4):\n",
    "        plt.contour(x1g,x2g,z, levels=[normalizer - offset], colors=col, linewidths=2.0, linestyles='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **two_features_plot** takes an input two features and a label, and displays the distribution for the specified winery and pair of features.\n",
    "\n",
    "The first line allows you to specify the parameters interactively using sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69cd39abba1405495e705f127d55381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1), label=IntSlider(1,1,3,1) )\n",
    "def two_features_plot(f1,f2,label):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[trainy==label,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[trainy==label,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(trainx[trainy==label, f1], trainx[trainy==label, f2], 'ro')\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Now plot a few contour lines of the density\n",
    "    mu, cov = fit_gaussian(trainx[trainy==label,:], [f1,f2])\n",
    "    plot_contours(mu, cov, x1g, x2g, 'k')\n",
    "    \n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Class ' + str(label), fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that will fit a Gaussian generative model to the three classes, restricted to a given list of features. The function returns:\n",
    "* `mu`: the means of the Gaussians, one per row\n",
    "* `covar`: covariance matrices of each of the Gaussians\n",
    "* `pi`: list of three class weights summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(x, y, features):\n",
    "    k = 3 # number of classes\n",
    "    d = len(features) # number of features\n",
    "    mu = np.zeros((k+1,d)) # list of means\n",
    "    covar = np.zeros((k+1,d,d)) # list of covariance matrices\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label,:], covar[label,:,:] = fit_gaussian(x[indices,:], features)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, covar, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the three Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d5d1a5b1cb4c2091c07314ac5ed513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def three_class_plot(f1,f2):\n",
    "    if f1 == f2: # we need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    \n",
    "    # Set up plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim(x1_lower, x1_upper) # limit along x1-axis\n",
    "    plt.ylim(x2_lower, x2_upper) # limit along x2-axis\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a grid along each axis; the density will be computed at each grid point\n",
    "    res = 200 # resolution\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Show the Gaussian fit to each class, using features f1,f2\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    for label in range(1,4):\n",
    "        gmean = mu[label,:]\n",
    "        gcov = covar[label,:,:]\n",
    "        plot_contours(gmean, gcov, x1g, x2g, colors[label-1])\n",
    "\n",
    "    # Finally, display\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.title('Wine data', fontsize=14, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we can predict the class (1,2,3) based just on these two features?\n",
    "\n",
    "We start with a testing procedure that is analogous to what we developed in the 1-d case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c245eca9d94e18a99c9c18670a1355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='f1', max=12), IntSlider(value=6, description='f2', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "@interact( f1=IntSlider(0,0,12,1), f2=IntSlider(6,0,12,1) )\n",
    "def test_model(f1, f2):\n",
    "    if f1 == f2: # need f1 != f2\n",
    "        print(\"Please choose different features for f1 and f2.\")\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, features)\n",
    "    \n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    nt = len(testy) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(testx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print(\"Test error using feature(s): \")\n",
    "    for f in features:\n",
    "        print(\"'\" + featurenames[f] + \"'\" + \" \",)\n",
    "    print()\n",
    "    print(\"Errors: \" + str(errors) + \"/\" + str(nt))# Now test the performance of a predictor based on a subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different pairs of features yield different test errors.\n",
    "* What is the smallest achievable test error?\n",
    "* Which pair of features achieves this minimum test error?\n",
    "\n",
    "*Make a note of your answers to these questions, as you will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **show_decision_boundary** takes as input two features, builds a classifier based only on these two features, and shows a plot that contains both the training data and the decision boundary.\n",
    "\n",
    "To compute the decision boundary, a dense grid is defined on the two-dimensional input space and the classifier is applied to every grid point. The built-in `pyplot.contour` function can then be invoked to depict the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decision_boundary(f1,f2):\n",
    "    # Fit Gaussian to each class\n",
    "    mu, covar, pi = fit_generative_model(trainx, trainy, [f1,f2])\n",
    "    \n",
    "    # Set up dimensions of plot\n",
    "    x1_lower, x1_upper = find_range(trainx[:,f1])\n",
    "    x2_lower, x2_upper = find_range(trainx[:,f2])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "\n",
    "    # Plot points in training set\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        plt.plot(trainx[trainy==label,f1], trainx[trainy==label,f2], marker='o', ls='None', c=colors[label-1])\n",
    "\n",
    "    # Define a dense grid; every point in the grid will be classified according to the generative model\n",
    "    res = 200\n",
    "    x1g = np.linspace(x1_lower, x1_upper, res)\n",
    "    x2g = np.linspace(x2_lower, x2_upper, res)\n",
    "\n",
    "    # Declare random variables corresponding to each class density\n",
    "    random_vars = {}\n",
    "    for label in range(1,4):\n",
    "        random_vars[label] = multivariate_normal(mean=mu[label,:],cov=covar[label,:,:])\n",
    "\n",
    "    # Classify every point in the grid; these are stored in an array Z[]\n",
    "    Z = np.zeros((len(x1g), len(x2g)))\n",
    "    for i in range(0,len(x1g)):\n",
    "        for j in range(0,len(x2g)):\n",
    "            scores = []\n",
    "            for label in range(1,4):\n",
    "                scores.append(np.log(pi[label]) + random_vars[label].logpdf([x1g[i],x2g[j]]))\n",
    "            Z[i,j] = np.argmax(scores) + 1\n",
    "\n",
    "    # Plot the contour lines\n",
    "    plt.contour(x1g,x2g,Z.T,3,cmap='seismic')\n",
    "    \n",
    "    # Finally, show the image\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function above to draw the decision boundary using features 0 ('alcohol') and 6 ('flavanoids')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_decision_boundary(0,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add interactive sliders to function **show_decision_boundary**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a plot similar to that of **show_decision_boundary**, but in which just the **test** data is shown.\n",
    "Look back at your answer to *Fast exercise 1*. Is it corroborated by your plot? Are the errors clearly visible?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
